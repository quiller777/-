Task04
# 数理统计
统计学是收集、分析、表述和解释数据的科学，统计学是一门处理数据的方法和技术的学科
假设身高符合正态分布，这个正态分布中的 𝜇 和 𝜎2 的值是多少就是统计学做的事情，
而这个工作也叫做参数估计

## 1. 总体和样本
总体：研究对象的全体 （总体就是一个概率分布）
个体：构成总体的每个成员

抽样方法差异
以“简单随机抽样”为例：
- 从总体中抽取的样本具有代表性（同等机会选入样本）
- 从总体中抽取的样本具有独立性（每一个样本的取值不会影响其它样本取值，相互独立）

**在简单随机抽样这种抽样方法下，样本中的每一个样品 𝑥1,𝑥2,⋯,𝑥𝑛 之间独立同分布，
同分布于总体分布，简称：iid**

设总体 $X$ 具有分布函数 $F(x), x_{1}, x_{2}, \cdots, x_{n}$ 为取自该总体的容量为 $n$ 的样本，
则样本联合分布函数为：
$F\left(x_{1}, x_{2}, \cdots, x_{n}\right)=\prod_{i=1}^{n} F\left(x_{i}\right) .$

注意：很多情况下不能满足独立同分布的假设，比如时间序列数据，前后之间存在关联性

## 2. 经验分布函数和直方图
### （1） 经验分布函数
统计学的核心是适用样本信息来估计总体信息，由于总体信息存在未知特征，只能通过多次试验样本来推断总体。经验分布函数就是适用样本信息构造的分布函数来获得近似未知的总体分布函数。

设 $x_{1}, x_{2}, \cdots, x_{n}$ 是取自总体分布函数为 $F(x)$ 的样本， 若将样本观测值由小到大进行排列， 记为 $x_{(1)}, x_{(2)}, \cdots, x_{(n)}$, 则 $x_{(1)}, x_{(2)}, \cdots, x_{(n)}$ 称为有序样本， 用有序样本定义如下函数：
$$
F_{n}(x)= \begin{cases}0, & \text { 当 } x<x_{(1)}, \\ k / n, & \text { 当 } x_{(k)} \leqslant x<x_{(k+1)}, k=1,2, \cdots, n-1, \\ 1, & \text { 当 } x \geqslant x_{(n)},\end{cases}
$$
则 $F_{n}(x)$ 是一非减右连续函数， 且满足
$$
F_{n}(-\infty)=0 \text { 和 } F_{n}(\infty)=1 .
$$
由此可见， $F_{n}(x)$ 是一个分布函数， 称 $F_{n}(x)$ 为该样本的经验分布函数。

为什么样本信息可以推断总体？ **格纹利柯定理**

求经验分布函数的过程：
1.将样本排序
2.列出各部分的概率
### （2） 直方图
直方图是数值数据分布的精确图形表示
频数直方图（频数n)
频率直方图（频率p）
## 3. 统计量与三大抽样分布
### 3.1 统计量
直方图的图形方式无法数值化具体研究（比如比较两个总体某个特征大小）
进行数值化研究的最有效方式是构造样本的函数
不含有任何未知参数的样本函数都是统计量
统计量因样本而异，是随机变量，统计量的分布成为抽样分布
虽然统计量不依赖于任何参数，但是统计量的分布依赖于未知参数

常见统计量及对应抽样分布：
#### 3.1.1 样本均值
**统计量**
设 $x_{1}, x_{2}, \cdots, x_{n}$ 为取自某总体的样本， 其算术平均值称为样本均值，一 般用 $\bar{x}$ 表示，即
$$
\bar{x}=\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}=\frac{1}{n} \sum_{i=1}^{n} x_{i} 
$$
如果把样本中的数据与样本均值的差称为偏差， 则样本所有偏差之和为 0， 即 $\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)=0$。

**抽样分布**
设 $x_{1}, x_{2}, \cdots, x_{n}$ 是来自某个总体的样本， $\bar{x}$ 为样本均值。

（1）若总体分布为 $N\left(\mu, \sigma^{2}\right)$， 则 $\bar{x}$ 的精确分布为 $N\left(\mu, \sigma^{2} / n\right)$;

（2） 若总体分布末知或不是正态分布， $E(x)=\mu, \operatorname{Var}(x)=\sigma^{2}$ 存在， 则 $n$ 较大时 $\bar{x}$ 的渐近分布为 $N\left(\mu, \sigma^{2} / n\right)$。 这里渐近分布是指 $n$ 较大时的近似分布。

#### 3.1.2 样本方差与样本标准差
设 $x_{1}, x_{2}, \cdots, x_{n}$ 为取自某总体的样本，则它关于样本均值 $\bar{x}$ 的平均偏差平方和
$$
s_{n}^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}
$$
称为样本方差。

样本标准差就是样本方差的算术平方根，即：$s_{n}=\sqrt{s_{n}^{2}}$。

为了量纲一致，通常使用标准差进行分析度量

无偏方差：
$s^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}$

当样本量较大时，$s_n^2$与$s^2$相差不大，可以随意使用，
当样本量较小时，计算样本方差最好使用无偏样本方差$s^2$。

**分布**
设总体为 $X$ 方差存在， 即 $E(X)=\mu, \operatorname{Var}(X)=\sigma^{2}<\infty, x_{1}, x_{2}, \cdots, x_{n}$ 为 从该总体得到的样本， $\bar{x}$ 和 $s^{2}$ 分别是样本均值和样本方差, 则
$$
\begin{gathered}
E(\bar{x})=\mu, \quad \operatorname{Var}(\bar{x})=\sigma^{2} / n, \\
E\left(s^{2}\right)=\sigma^{2} .
\end{gathered}
$$
样本均值的期望与总体均值相同， 而样本均值的方差是总体方差的 $1 / n$

#### 3.1.3 次序统计量及其分布 （了解）
设 $x_{1}, x_{2}, \cdots, x_{n}$ 是取自总体 $X$ 的样本， $x_{(i)}$ 称为该样本的第 $i$ 个次序统计量， 它的取值是将样本观测值由小到大排列后得到的第 $i$ 个观测值。 其中 $x_{(1)}=$ $\min \left\{x_{1}, x_{2}, \cdots, x_{n}\right\}$ 称为该样本的最小次序统计量， $x_{(n)}=\max \left\{x_{1}, x_{2}, \cdots, x_{n}\right\}$ 称为该样本的最大次序统计量。

#### 3.1.4 样本分位数与样本中位数及其抽样分布
若 $n=5$， 则 $m_{0.5}=x_{(3)}$， 若 $n=6$, 则 $m_{0.5}=\frac{1}{2}\left(x_{(3)}+x_{(4)}\right)$

设总体密度函数为 $p(x), x_{p}$ 为其 $p$ 分位数， $p(x)$ 在 $x_{p}$ 处连续且 $p\left(x_{p}\right)>$ 0 ， 则当 $n \rightarrow \infty$ 时样本 $p$ 分位数 $m_{p}$ 的渐近分布为
$$
 N\left(x_{p}, \frac{p(1-p)}{n \cdot p^{2}\left(x_{p}\right)}\right) 
$$
特别地, 对于样本中位数来说, 当 $n \rightarrow \infty$ 时有
$$
N\left(x_{0.5}, \frac{1}{4 n \cdot p^{2}\left(x_{0.5}\right)}\right) 
$$
### 3.2 三大抽样分布
#### 3.2.1 卡方统计量与卡方分布

**可以用一句话记住卡方分布：$n$个标准正态分布的平方和服从自由度为$n$的卡方分布**。

#### 3.2.2 F统计量与F分布
设随机变量 $X_{1} \sim \chi^{2}(m), X_{2} \sim \chi^{2}(n), X_{1}$ 与 $X_{2}$ 独立， 则称 $F=\frac{X_{1} / m}{X_{2} / n}$ 的分布是自由度为 $m$ 与 $n$ 的 $F$ 分布， 记为 $F \sim F(m, n)$， 其中 $m$ 称为分子自由度， $n$ 称为分母自由度。F分布的密度函数为：
$$
\begin{aligned}
p_{F}(y) &=\frac{\Gamma\left(\frac{m+n}{2}\right)\left(\frac{m}{n}\right)^{\frac{m}{2}} y^{\frac{m}{2}-1}\left(1+\frac{m}{n} y\right)^{-\frac{m+n}{2}}}{\Gamma\left(\frac{m}{2}\right) \Gamma\left(\frac{n}{2}\right)} \cdot
\end{aligned}
$$
#### 3.2.3 t分布及其统计量
设随机变量 $X_{1}$ 与 $X_{2}$ 独立且 $X_{1} \sim N(0,1), X_{2} \sim \chi^{2}(n)$, 则称 $t=\frac{X_{1}}{\sqrt{X_{2} / n}}$ 的分布为自由度为 $n$ 的 $t$ 分布， 记为 $t \sim t(n)$。

设 $x_{1}, x_{2}, \cdots, x_{n}$ 是来自正态分布 $N\left(\mu, \sigma^{2}\right)$ 的一个样本， $\bar{x}$ 与 $s^{2}$ 分别是该样本的样本均值与样本方差， 则有
$$
t=\frac{\sqrt{n}(\bar{x}-\mu)}{s} \sim t(n-1) 
$$
𝑡 分布 开创了小样本统计推断的新纪元， 小样本统计分析由此引起了广大统计科研工作者的重视。

## 4. 参数估计之点估计的概念
为什么学习统计量？
使用样本信息取推断总体的信息

而统计量只含有样本的信息，不含未知的总体参数。如何对未知的总体进行推断呢？
通过样本统计量对总体分布的未知参数进行估计

点估计希望使用一个数估计总体中的位置参数，
区间估计指的是使用一个区间估计总体中的参数，区间估计解决了点估计无法评价估计的精度的问题，

设 $x_{1}, x_{2}, \cdots, x_{n}$ 是来自总体的一个样本， 用于估计未知参数 $\theta$ 的统计量 $\hat{\theta}=\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ 称为 $\theta$ 的估计量， 或称为 $\theta$ 的点估计， 简称估计。

## 5. 参数估计之点估计的方法：矩估计
### 5.1 总体矩和中心矩

设 $X$ 为随机变量， $k$ 为正整数。 如果以下的数学期望都存在， 则称
$$
\mu_{k}=E\left(X^{k}\right)
$$
为 $X$ 的 $k$ 阶原点矩。 称
$$
\nu_{k}=E(X-E(X))^{k}
$$
为 $X$ 的 $k$ 阶中心矩。
数学期望是随机变量的1阶原点矩，方差是随机变量的2阶中心矩。
随机变量的矩是随机变量的一类数字特征，随机变量的原点矩刻画了随机变量$X$偏离原点$(0,0)$的程度，
而中心矩描述了随机变量$X$偏离“中心”的程度，可以使用数学期望和方差做类比

设 $x_{1}, x_{2}, \cdots, x_{n}$ 是样本， $k$ 为正整数， 则统计量
$$
a_{k}=\frac{1}{n} \sum_{i=1}^{n} x_{i}^{k}
$$
称为样本 $k$ 阶原点矩。 特别地， 样本一阶原点矩就是样本均值。 统计量
$$
b_{k}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{k}
$$
称为样本 $k$ 阶中心矩。 特别地， 样本二阶中心矩就是样本方差。

### 5.2 矩估计
使用样本矩（样本原点矩和样本中心矩）替换总体矩（原点矩和中心矩），
如：使用样本均值 𝑥¯ 替换总体均值 𝐸(𝑋) 、使用样本方差 𝑠2 替换总体方差 𝑉𝑎𝑟(𝑋) 。

## 6. 参数估计之点估计的方法：极大似然估计
利用已知的样本结果信息，反推最有可能（最大概率）导致这些样本结果出现的模型参数值

正态分布的$\mu$和$\sigma^2$的极大似然估计竟然是样本均值$\bar{x}$和有偏样本方差$s_n^2$，这就将我们的估计与统计量连接起来了。
**一般来说，估计的结果都与从该分布抽样的样本组成的样本统计量有关，如样本均值$\bar{x}$样本方差$s^2$** 等等。

## 7. 参数估计之点估计的方法：无偏性与有效性
如何评价统计量的估计好坏：
### 7.1 无偏性

设 $\hat{\theta}=\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ 是 $\theta$ 的一个估计， $\theta$ 的参数空间为 $\Theta$， 若对任意的 $\theta \in \Theta$， 有
$$
E_{\theta}(\hat{\theta})=\theta,
$$
则称 $\hat{\theta}$ 是 $\theta$ 的无偏估计， 否则称为有偏估计。

### 7.2有效性
设 $\hat{\theta}_{1}, \hat{\theta}_{2}$ 是 $\theta$ 的两个无偏估计， 如果对任意的 $\theta \in \Theta$ 有
$$
\operatorname{Var}\left(\hat{\theta}_{1}\right) \leqslant \operatorname{Var}\left(\hat{\theta}_{2}\right),
$$
且至少有一个 $\theta \in \Theta$ 使得上述不等号严格成立， 则称 $\hat{\theta}_{1}$ 比 $\hat{\theta}_{2}$ 有效。

## 8.参数估计之区间估计（了解）

## 9. 假设检验之基本思想
## 9.1 假设检验的概念
假设检验是对某一个说法做出检验，提出这个说法是正确还是错误
给出一个命题，给出命题是接受还是拒绝。

## 9.2 假设检验的步骤
### （1）建立假设
### （2）选择统计量并给出拒绝域形式
当拒绝域确定以后，如果某次的样本统计量位于拒绝域 𝑊 则拒绝原假设，如果某次的统计量位于接受域 𝑊¯ 则接受原假设。
### （3）选择显著性水平
当 $\theta \in \Theta_{0}$ 时， 样本由于随机性却落人了拒绝域 $W$， 于是我们采取了拒绝 $H_{0}$ 的错误决策， 称这样的错误为第一类错误。
当 $\theta \in \Theta_{1}$ 时， 样本却落人了接受域 $\bar{W}$， 于是我们采取了接受 $H_{0}$ 的错误决策， 称这样的错误为第二类错误。
既然会犯两类错误，我们可以计算犯两类错误的概率，即：
   - 犯第一类错误概率: $\alpha(\theta)=P_{\theta}\{\boldsymbol{X} \in W\}, \theta \in \Theta_{0}$。
   - 犯第二类错误概率: $\beta(\theta)=P_{\theta}\{X \in \bar{W}\}, \theta \in \Theta_{1}$。
### (4) 给出拒绝域

### 假设检验的一般步骤
 - 建立原假设于备择假设；
- 选择合适的统计量解决检验问题；
- 写出拒绝域的形式和显著性水平（一类错误的概率 𝛼 ）；
- 计算拒绝域边界的统计量分布的分位数；
- 观察统计量值是否位于拒绝域，位于拒绝域则拒绝原假设，否则接受原假设。


## 10.假设检验之正态总体参数的假设检验
### 10.1 单个正态总体均值的检验
#### 10.1.1 某个正态总体均值的检验
设 $x_{1}, x_{2}, \cdots, x_{n}$ 是来自 $N\left(\mu, \sigma^{2}\right)$ 的样本，关于 $\mu$ 的检验问题有以下三种:

I $H_{0}: \mu \leqslant \mu_{0}$ vs $H_{1}: \mu>\mu_{0}$,

II $H_{0}: \mu \geqslant \mu_{0}$ vs $H_{1}: \mu<\mu_{0}$,

III $H_{0}: \mu=\mu_{0}$ vs $H_{1}: \mu \neq \mu_{0}$,

（a）$\sigma=\sigma_{0}$ 已知时的 $u$ 检验：
检验（z检验）完成的是当总体方差已知条件下的单个正态总体均值的检验，

（b）$\sigma$未知的单样本t检验：
在实际中大多数情况下总体方差都是未知的，因此当总体方差未知时，u检验（z检验）将失效，取而代之的是t检验。

p值是指根据样本所能计算出来的最小的一类错误概率值（显著性水平），如果我们设定的一类错误的概率$\alpha$大于p值，那么拒绝原假设！如：$\alpha=0.05,\quad p=0,002$，由于$p < \alpha$则拒绝原假设。可以简记：
$$
p < \alpha=0.05, \text{拒绝原假设}
$$

#### 10.2 两个正态总体均值差的检验

（a）$\sigma_{1}, \sigma_{2}$ 已知时的两样本 $u$ 检验：

（b）$\sigma$ 未知时的两样本 $t$ 检验：

#### 10.3 正态总体方差的检验

（a）单个正态总体方差的 $\chi^{2}$ 检验：

（b）两个正态总体方差比的 $F$ 检验：

## 11. 假设检验之似然比检验与Bootstrap方法

设 $x_{1}, x_{2}, \cdots, x_{n}$ 为来自密度函数为 $p(x ; \theta), \theta \in \Theta$ 的总体的样本， 考虑如下检验问题:
$$
H_{0}: \theta \in \Theta_{0} \quad \text { vs } \quad H_{1}: \theta \in \Theta_{1}=\Theta-\Theta_{0}
$$
令
$$
\Lambda\left(x_{1}, x_{2}, \cdots, x_{n}\right)=\frac{\sup _{\theta \in \Theta} p\left(x_{1}, x_{2}, \cdots, x_{n} ; \theta\right)}{\sup _{\theta \in \Theta_{0}} p\left(x_{1}, x_{2}, \cdots, x_{n} ; \theta\right)},
$$
则我们称统计量 $\Lambda\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ 为假设的似然比 ( likelihood ratio), 有时也称之为广义似然比。
$\Lambda\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ 也可以写成如下形式：
$$
\Lambda\left(x_{1}, x_{2}, \cdots, x_{n}\right)=\frac{p\left(x_{1}, x_{2}, \cdots, x_{n} ; \hat{\theta}\right)}{p\left(x_{1}, x_{2}, \cdots, x_{n} ; \hat{\theta}_{0}\right)},
$$
其中 $\hat{\theta}$ 表示在全参数空间 $\Theta$ 上 $\theta$ 的最大似然估计， $\hat{\theta}_{0}$ 表示在子参数空间 $\Theta_{0}$ 上 $\theta$ 的最大似然估计。也就是说, $\Lambda\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ 的分子表示没有假设时的似然函数最大值，分母表示在原假设成立条件下的似然函数最大值。

似然比检验需要确定2倍似然比统计量分布的近似分布———卡方分布的自由度。
如果分布的自由度难以确定，这个方法将难以进行下去。